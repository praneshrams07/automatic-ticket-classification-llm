# Automatic Ticket Classification + LLM Reply (Gemini)

An end-to-end **customer support automation pipeline** that:
1) **Classifies** incoming ticket text into the correct **support queue/department** using a fine-tuned **XLM-R (Transformer)** model, and  
2) **Drafts a polite acknowledgement reply** using **Google Gemini**, with a safe **fallback template** when Gemini is unavailable.

> Dataset: `Tobi-Bueck/customer-support-tickets` (Hugging Face)

---

## ‚ú® What this project does

‚úÖ **Ticket Routing (Multi-class Classification)**  
- Input: ticket `body` text  
- Output: predicted `queue` (52 categories)  
- Model: **XLM-R (xlm-roberta-base)** fine-tuned for sequence classification  
- Also returns **Top-K predictions** + **confidence score**

‚úÖ **Confidence-based Triage**  
- If confidence ‚â• threshold ‚Üí **AUTO route**  
- Else ‚Üí **NEEDS_REVIEW** (human verification)

‚úÖ **Auto Reply Generation (Gemini)**  
- Sends ticket text + predicted queue to Gemini  
- Generates a short, professional acknowledgement  
- If Gemini quota/key is missing ‚Üí **fallback reply** (no crash)

‚úÖ **Streamlit UI**  
- Paste ticket text  
- Get queue + confidence + top predictions  
- Get a drafted response (Gemini / fallback)

---

## üß† Why XLM-R?
The dataset includes multiple languages (e.g., **English + German**).  
**XLM-R** handles multilingual text better than traditional LSTM baselines.

---

## üìÅ Project Structure
```
automatic-ticket-classification-llm/
‚îú‚îÄ app.py # Streamlit demo app (XLM-R + Gemini)
‚îú‚îÄ src/
‚îÇ ‚îú‚îÄ final_pipeline_gemini.py # CLI pipeline (predict + reply)
‚îÇ ‚îú‚îÄ test_gemini.py # Quick Gemini sanity check
‚îÇ ‚îî‚îÄ (other scripts)
‚îú‚îÄ models/
‚îÇ ‚îú‚îÄ xlmr_ticket_classifier/ # Saved Hugging Face model folder
‚îÇ ‚îÇ ‚îú‚îÄ config.json
‚îÇ ‚îÇ ‚îú‚îÄ model.safetensors
‚îÇ ‚îÇ ‚îú‚îÄ tokenizer.json
‚îÇ ‚îÇ ‚îú‚îÄ label_encoder.pkl
‚îÇ ‚îÇ ‚îî‚îÄ meta.pkl
‚îÇ ‚îî‚îÄ (other models if any)
‚îú‚îÄ requirements.txt
‚îî‚îÄ README.md
```
> ‚ö†Ô∏è Model weights are large. Consider using `.gitignore` to avoid pushing heavy files to GitHub.

---

## ‚öôÔ∏è Setup

### 
1) Create and activate a virtual environment (macOS)
```bash
python3 -m venv .venv
source .venv/bin/activate
```
2) Install dependencies
pip install -r requirements.txt

3) (Optional) Set Gemini API key
export GEMINI_API_KEY="YOUR_API_KEY"
If GEMINI_API_KEY is not set, the pipeline will automatically use a fallback reply.

```bash
## üñ•Ô∏è Run the Streamlit App
streamlit run app.py
```


Then open the URL shown in terminal.